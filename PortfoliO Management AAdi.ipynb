{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Step 1: Generate synthetic stock price data for 10 stocks\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range(start='2024-01-01', periods=252)  # 252 trading days\n",
    "stocks = {\n",
    "    'Stock_A': np.cumsum(np.random.normal(0, 1, len(dates))) + 100,\n",
    "    'Stock_B': np.cumsum(np.random.normal(0, 1, len(dates))) + 120,\n",
    "    'Stock_C': np.cumsum(np.random.normal(0, 1, len(dates))) + 140,\n",
    "    'Stock_D': np.cumsum(np.random.normal(0, 1, len(dates))) + 160,\n",
    "    'Stock_E': np.cumsum(np.random.normal(0, 1, len(dates))) + 180,\n",
    "    'Stock_F': np.cumsum(np.random.normal(0, 1, len(dates))) + 200,\n",
    "    'Stock_G': np.cumsum(np.random.normal(0, 1, len(dates))) + 220,\n",
    "    'Stock_H': np.cumsum(np.random.normal(0, 1, len(dates))) + 240,\n",
    "    'Stock_I': np.cumsum(np.random.normal(0, 1, len(dates))) + 260,\n",
    "    'Stock_J': np.cumsum(np.random.normal(0, 1, len(dates))) + 280\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "prices = pd.DataFrame(stocks, index=dates)\n",
    "prices.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f0a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Calculate daily returns\n",
    "returns = prices.pct_change().dropna()\n",
    "returns.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e3c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Standardize the returns data\n",
    "scaler = StandardScaler()\n",
    "scaled_returns = scaler.fit_transform(returns)\n",
    "\n",
    "# Step 4: Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(scaled_returns)\n",
    "\n",
    "# Step 5: Determine optimal number of clusters using the silhouette score\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(reduced_data)\n",
    "    score = silhouette_score(reduced_data, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "plt.title('Silhouette Score for Different Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1754b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Apply KMeans clustering with optimal clusters (based on silhouette score)\n",
    "optimal_clusters = np.argmax(silhouette_scores) + 2\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(reduced_data)\n",
    "\n",
    "# Add clusters to the DataFrame\n",
    "returns['Cluster'] = clusters\n",
    "returns.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dcd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Visualize the clusters using PCA components\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=reduced_data[:, 0], y=reduced_data[:, 1], hue=clusters, palette='viridis', marker='o')\n",
    "plt.title('Stock Clusters using KMeans and PCA')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb32bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Analyze portfolio composition based on clusters\n",
    "cluster_summary = returns.groupby('Cluster').mean().T\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cluster_summary, annot=True, cmap='coolwarm')\n",
    "plt.title('Average Returns for Each Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73df7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Construct equal-weighted portfolio for each cluster\n",
    "portfolio_returns = {}\n",
    "for cluster in range(optimal_clusters):\n",
    "    cluster_stocks = returns[returns['Cluster'] == cluster].iloc[:, :-1]\n",
    "    portfolio_returns[f'Portfolio_{cluster}'] = cluster_stocks.mean(axis=1)\n",
    "\n",
    "# Create a DataFrame for portfolio returns\n",
    "portfolio_df = pd.DataFrame(portfolio_returns)\n",
    "portfolio_df['Total_Portfolio'] = portfolio_df.mean(axis=1)\n",
    "\n",
    "# Calculate cumulative returns\n",
    "cumulative_returns = (1 + portfolio_df).cumprod()\n",
    "\n",
    "# Step 10: Plot cumulative returns of each portfolio\n",
    "plt.figure(figsize=(12, 8))\n",
    "for column in cumulative_returns.columns:\n",
    "    plt.plot(cumulative_returns.index, cumulative_returns[column], label=column)\n",
    "plt.title('Cumulative Returns of Cluster-Based Portfolios')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
